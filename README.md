#
https://www.twman.org/AI/CV

https://huggingface.co/DeepLearning101
#

<details open>
<summary><strong>æ‰‹æŠŠæ‰‹å¸¶ä½ ä¸€èµ·è¸©AIå‘ï¼šhttps://blog.twman.org/p/deeplearning101.html</strong></summary>
   
- [é‚£äº› AI Agent è¦è¸©çš„å‘](https://blog.twman.org/2025/03/AIAgent.html)ï¼šæ·ºé¡¯ä»‹ç´¹ç”Ÿæˆå¼äººå·¥æ™ºæ…§æ ¸å¿ƒæ¦‚å¿µï¼Œå¼·èª¿ç¡¬é«”è³‡æºå’Œæ•¸æ“šçš„é‡è¦æ€§ã€‚
   - ä»‹ç´¹ç”Ÿæˆå¼äººå·¥æ™ºæ…§ï¼ˆGenAIï¼‰çš„æ ¸å¿ƒæ¦‚å¿µï¼ŒåŒ…æ‹¬å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€æç¤ºè©è¨­è¨ˆï¼ˆPromptï¼‰ã€æª¢ç´¢å¢å¼·ç”Ÿæˆï¼ˆRAGï¼‰ã€å¾®èª¿ï¼ˆFine-Tuningï¼‰ã€åŠŸèƒ½èª¿ç”¨ï¼ˆFunction Callingï¼‰ã€å·¥ä½œæµç¨‹ï¼ˆWorkflowï¼‰ã€ä»£ç†äººï¼ˆAgenticï¼‰å’Œå¤šæ¨¡æ…‹ï¼ˆMultimodalï¼‰ç­‰ã€‚
   - åˆ†äº«é€™äº›æŠ€è¡“åœ¨å¯¦éš›æ‡‰ç”¨ä¸­çš„ç¶“é©—ï¼Œä¸¦å¼·èª¿äº†ç¡¬é«”è³‡æºå’Œæ•¸æ“šåœ¨é–‹ç™¼éç¨‹ä¸­çš„é‡è¦æ€§ã€‚
     
- [ç™½è©±æ–‡æ‰‹æŠŠæ‰‹å¸¶ä½ ç§‘æ™® GenAI](https://blog.twman.org/2024/08/LLM.html)ï¼šæ·ºé¡¯ä»‹ç´¹ç”Ÿæˆå¼äººå·¥æ™ºæ…§æ ¸å¿ƒæ¦‚å¿µï¼Œå¼·èª¿ç¡¬é«”è³‡æºå’Œæ•¸æ“šçš„é‡è¦æ€§ã€‚
   - ä»‹ç´¹ç”Ÿæˆå¼äººå·¥æ™ºæ…§ï¼ˆGenAIï¼‰çš„æ ¸å¿ƒæ¦‚å¿µï¼ŒåŒ…æ‹¬å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€æç¤ºè©è¨­è¨ˆï¼ˆPromptï¼‰ã€æª¢ç´¢å¢å¼·ç”Ÿæˆï¼ˆRAGï¼‰ã€å¾®èª¿ï¼ˆFine-Tuningï¼‰ã€åŠŸèƒ½èª¿ç”¨ï¼ˆFunction Callingï¼‰ã€å·¥ä½œæµç¨‹ï¼ˆWorkflowï¼‰ã€ä»£ç†äººï¼ˆAgenticï¼‰å’Œå¤šæ¨¡æ…‹ï¼ˆMultimodalï¼‰ç­‰ã€‚
   - åˆ†äº«é€™äº›æŠ€è¡“åœ¨å¯¦éš›æ‡‰ç”¨ä¸­çš„ç¶“é©—ï¼Œä¸¦å¼·èª¿äº†ç¡¬é«”è³‡æºå’Œæ•¸æ“šåœ¨é–‹ç™¼éç¨‹ä¸­çš„é‡è¦æ€§ã€‚

- [å¤§å‹èªè¨€æ¨¡å‹ç›´æ¥å°±æ‰“å®Œæ”¶å·¥ï¼Ÿ](https://blog.twman.org/2024/09/LLM.html)ï¼šå›é¡§ LLM é ˜åŸŸæ¢ç´¢æ­·ç¨‹ï¼Œè¨è«–ç¡¬é«”å‡ç´šå° AI é–‹ç™¼çš„é‡è¦æ€§ã€‚
   - å›é¡§åœ¨å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰é ˜åŸŸçš„æ¢ç´¢æ­·ç¨‹ï¼Œåˆ†äº«äº†åœ¨èªéŸ³è­˜åˆ¥ã€æ–‡æœ¬åˆ†é¡ç­‰å¤šå€‹è‡ªç„¶èªè¨€è™•ç†ï¼ˆNLPï¼‰ä»»å‹™ä¸­çš„å¯¦è¸ç¶“é©—ã€‚
   - éš¨è‘— LLM çš„å‡ºç¾ï¼Œè¨±å¤šéå»éœ€è¦è¤‡é›œè™•ç†çš„ä»»å‹™è®Šå¾—æ›´åŠ ç°¡å–®ï¼Œä¸¦è¨è«–äº†ç¡¬é«”å‡ç´šå° AI é–‹ç™¼çš„é‡è¦æ€§ã€‚

- [é‚£äº›æª¢ç´¢å¢å¼·ç”Ÿæˆè¦è¸©çš„å‘](https://blog.twman.org/2024/07/RAG.html)ï¼šæ¢è¨ RAG æŠ€è¡“æ‡‰ç”¨èˆ‡æŒ‘æˆ°ï¼Œæä¾›å¯¦ç”¨ç¶“é©—åˆ†äº«å’Œå·¥å…·å»ºè­°ã€‚
   - æ¢è¨äº†æª¢ç´¢å¢å¼·ç”Ÿæˆï¼ˆRetrieval-Augmented Generation, RAGï¼‰æŠ€è¡“çš„æ‡‰ç”¨èˆ‡æŒ‘æˆ°ï¼Œç‰¹åˆ¥æ˜¯çµåˆçŸ¥è­˜åœ–è­œçš„ GraphRAG æ–¹æ³•ã€‚ â€‹
   - åˆ†äº«åœ¨æœ¬åœ°ç«¯éƒ¨ç½²å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç¶“é©—ï¼Œä¸¦å¼·èª¿äº†ç¡¬é«”è³‡æºçš„é‡è¦æ€§ã€‚
   - é‚„ä»‹ç´¹å¦‚ä½•æœ‰æ•ˆåœ°å°‡æ–‡æª”æ‹†åˆ†ç‚ºç‰‡æ®µï¼ˆchunkï¼‰ï¼Œä¸¦ä½¿ç”¨åµŒå…¥æ¨¡å‹å’Œé‡æ–°æ’åºå™¨ï¼ˆRerankerï¼‰ä¾†æå‡æª¢ç´¢çµæœçš„æº–ç¢ºæ€§ã€‚ â€‹
   - æä¾›å¤šç¨®é–‹æºå·¥å…·çš„æ¨è–¦ï¼Œå¦‚ Ollamaã€xinference å’Œ MinerUï¼Œä¾†å”åŠ©è™•ç† PDF ç­‰éçµæ§‹åŒ–è³‡æ–™ã€‚
   - æ–‡ç« å¼·èª¿äº†åœ¨å¯¦æ–½ RAG æŠ€è¡“æ™‚éœ€æ³¨æ„çš„å„ç¨®æŒ‘æˆ°ï¼Œä¸¦æä¾›äº†å¯¦ç”¨çš„ç¶“é©—åˆ†äº«å’Œå·¥å…·å»ºè­°ã€‚
  
- [é‚£äº›å¤§å‹èªè¨€æ¨¡å‹è¦è¸©çš„å‘](https://blog.twman.org/2024/02/LLM.html)ï¼šæ¢è¨å¤šç¨® LLM å·¥å…·çš„æ‡‰ç”¨èˆ‡æŒ‘æˆ°ï¼Œå¼·èª¿ç¡¬é«”è³‡æºçš„é‡è¦æ€§ã€‚
   - æ¢è¨å¤šç¨®å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰å·¥å…·çš„æ‡‰ç”¨èˆ‡æŒ‘æˆ°ï¼ŒåŒ…æ‹¬ Ollamaã€Difyã€OpenManusã€LangFlowã€Flowiseã€RAGFlowã€AnythingLLMã€CrewAI å’Œ AutoGenã€‚
   - åˆ†äº«é€™äº›å·¥å…·åœ¨å¯¦éš›æ‡‰ç”¨ä¸­çš„ç¶“é©—ï¼Œä¸¦æŒ‡å‡ºéƒ¨åˆ†å·¥å…·åœ¨ç©©å®šæ€§å’Œå®‰è£éç¨‹ä¸­å¯èƒ½é‡åˆ°çš„å›°é›£ã€‚
   - å¼·èª¿äº†ç¡¬é«”è³‡æºåœ¨ LLM é–‹ç™¼ä¸­çš„é‡è¦æ€§ï¼Œä¸¦æä¾›äº†ç¡¬é«”å‡ç´šçš„å»ºè­°ã€‚       

- [Large Language Modelï¼ŒLLM](https://blog.twman.org/2023/04/GPT.html)ï¼šæ¢è¨ LLM çš„ç™¼å±•èˆ‡æ‡‰ç”¨ï¼Œå¼·èª¿ç¡¬é«”è³‡æºåœ¨é–‹ç™¼ä¸­çš„é—œéµä½œç”¨ã€‚
   - æ¢è¨å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç™¼å±•èˆ‡æ‡‰ç”¨ï¼Œç‰¹åˆ¥æ˜¯ OpenAI çš„ GPT-3 å’Œ ChatGPT çš„å½±éŸ¿åŠ›ã€‚
   - è©³ç´°èªªæ˜äº†è¨“ç·´é€™äº›æ¨¡å‹æ‰€éœ€çš„é¾å¤§è³‡æºï¼Œä¾‹å¦‚ï¼Œè¨“ç·´ GPT-3 æ¨¡å‹éœ€è¦ä½¿ç”¨ 1,024 å¼µ A100 GPUï¼Œè€—æ™‚ 24 å¤©ã€‚
   - å¼·èª¿ç¡¬é«”è³‡æºåœ¨ LLM é–‹ç™¼ä¸­çš„é—œéµä½œç”¨ï¼Œä¸¦åˆ†äº«äº†ä½œè€…åœ¨ç¡¬é«”å‡ç´šæ–¹é¢çš„ç¶“é©—ã€‚
     
- [ComfyUI + Stable Diffuision](https://blog.twman.org/2024/11/diffusion.html)ï¼šæ·±å…¥æ¢è¨å½±åƒç”Ÿæˆèˆ‡åˆ†å‰²æŠ€è¡“çš„æ‡‰ç”¨ï¼Œå¼·èª¿ç¡¬é«”è³‡æºçš„é‡è¦æ€§ã€‚
   - æ·±å…¥æ¢è¨äº†å¤šç¨®å½±åƒç”Ÿæˆèˆ‡åˆ†å‰²æŠ€è¡“çš„æ‡‰ç”¨èˆ‡ç™¼å±•ï¼Œç‰¹åˆ¥æ˜¯ ComfyUIã€Stable Diffusionã€FLUXã€Segment Anything Model 2ï¼ˆSAM2ï¼‰ç­‰å·¥å…·çš„çµåˆä½¿ç”¨ã€‚
   - åˆ†äº«å¯¦éš›æ‡‰ç”¨ä¸­çš„ç¶“é©—ï¼Œä¸¦å¼·èª¿äº†ç¡¬é«”è³‡æºåœ¨å½±åƒè™•ç†ä»»å‹™ä¸­çš„é‡è¦æ€§ã€‚
   - ä»‹ç´¹äº†å¤šæ¨¡æ…‹æ¨¡å‹çš„æ‡‰ç”¨ï¼Œå±•ç¤ºäº†å¦‚ä½•åŒæ™‚è™•ç†æ–‡æœ¬ã€å½±åƒç­‰å¤šç¨®æ•¸æ“šå½¢å¼ï¼Œä»¥æå‡å½±åƒç”Ÿæˆèˆ‡åˆ†å‰²çš„æ•ˆæœã€‚

- [é‚£äº›ASRå’ŒTTSå¯èƒ½æœƒè¸©çš„å‘](https://blog.twman.org/2024/02/asr-tts.html)æ¢è¨ ASR å’Œ TTS æŠ€è¡“æ‡‰ç”¨ä¸­çš„å•é¡Œï¼Œå¼·èª¿æ•¸æ“šè³ªé‡çš„é‡è¦æ€§ã€‚
   - æ¢è¨äº†åœ¨è‡ªå‹•èªéŸ³è­˜åˆ¥ï¼ˆASRï¼‰å’Œæ–‡æœ¬è½‰èªéŸ³ï¼ˆTTSï¼‰æŠ€è¡“æ‡‰ç”¨ä¸­å¯èƒ½é‡åˆ°çš„å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆã€‚
   - åˆ†äº«åœ¨å¯¦éš›å•†æ¥­å ´æ™¯ä¸­ä½¿ç”¨ OpenAI çš„ Whisper æ¨¡å‹çš„ç¶“é©—ï¼Œä¸¦å¼·èª¿äº†å¾®èª¿æ¨¡å‹ä»¥æå‡ä¸­æ–‡èªéŸ³è­˜åˆ¥æ•ˆæœçš„é‡è¦æ€§ã€‚
   - æ–‡ç« ä»‹ç´¹äº†å¤šç¨®é–‹æºå·¥å…·ï¼Œå¦‚ faster-whisperã€WhisperX å’Œ BELLE-2ï¼Œé€™äº›å·¥å…·å¯ç”¨æ–¼å„ªåŒ– ASR å’Œ TTS çš„æ€§èƒ½ã€‚
   - å¼·èª¿æ•¸æ“šè³ªé‡åœ¨æ¨¡å‹è¨“ç·´ä¸­çš„é—œéµä½œç”¨ï¼Œä¸¦æä¾›äº†è™•ç†å’Œè¨“ç·´æ•¸æ“šçš„å·¥å…·èˆ‡æŠ€å·§ã€‚
     
- [é‚£äº›è‡ªç„¶èªè¨€è™•ç†è¸©çš„å‘](https://blog.twman.org/2021/04/NLP.html)ï¼šåˆ†äº« NLP é ˜åŸŸçš„å¯¦è¸ç¶“é©—ï¼Œå¼·èª¿æ•¸æ“šè³ªé‡å°æ¨¡å‹æ•ˆæœçš„å½±éŸ¿ã€‚
   - åˆ†äº«åœ¨è‡ªç„¶èªè¨€è™•ç†ï¼ˆNLPï¼‰é ˜åŸŸçš„å¯¦è¸ç¶“é©—ï¼Œæ¶µè“‹æ–‡æœ¬ç³¾éŒ¯ã€æ–‡æœ¬åˆ†é¡ã€æ–‡æœ¬ç›¸ä¼¼åº¦ã€å‘½åå¯¦é«”è­˜åˆ¥ã€æ–‡æœ¬æ‘˜è¦å’Œæ©Ÿå™¨é–±è®€ç†è§£ç­‰æ‡‰ç”¨ã€‚
   - å¼·èª¿æ•¸æ“šè³ªé‡å°æ¨¡å‹æ•ˆæœçš„é—œéµå½±éŸ¿ï¼Œä¸¦æŒ‡å‡ºåœ¨æ·±åº¦å­¸ç¿’èˆˆèµ·å‰ï¼Œå·²æœ‰å¤šç¨®æ¼”ç®—æ³•å¯ä¾›ä½¿ç”¨ã€‚
   - æ–‡ç« æåˆ° BERT ç­‰æ¨¡å‹çš„å‡ºç¾å° NLP é ˜åŸŸçš„é‡å¤§å½±éŸ¿ï¼Œä¸¦å»ºè­°è®€è€…äº†è§£ç›¸é—œæŠ€è¡“ã€‚

- [é‚£äº›èªéŸ³è™•ç† (Speech Processing) è¸©çš„å‘](https://blog.twman.org/2021/04/ASR.html)ï¼šåˆ†äº«èªéŸ³è™•ç†é ˜åŸŸçš„å¯¦å‹™ç¶“é©—ï¼Œå¼·èª¿è³‡æ–™å“è³ªå°æ¨¡å‹æ•ˆæœçš„å½±éŸ¿ã€‚
   - åˆ†äº«åœ¨èªéŸ³è™•ç†é ˜åŸŸçš„å¯¦å‹™ç¶“é©—ï¼Œæ¶µè“‹äº†èªªè©±è€…è¾¨è­˜ã€èªéŸ³å¢å¼·ã€èªéŸ³åˆ†é›¢ç­‰å¤šå€‹é¢å‘ã€‚
   - å¼·èª¿è³‡æ–™å“è³ªå°æ¨¡å‹æ•ˆæœçš„é—œéµå½±éŸ¿ï¼Œä¸¦æŒ‡å‡ºåœ¨æ·±åº¦å­¸ç¿’èˆˆèµ·ä¹‹å‰ï¼Œå·²æœ‰å¤šç¨®æ¼”ç®—æ³•å¯ä¾›ä½¿ç”¨ã€‚
   - æ–‡ç« æåˆ°ç¡¬é«”è³‡æºåœ¨èªéŸ³è™•ç†ä»»å‹™ä¸­çš„é‡è¦æ€§ï¼Œåˆ†äº«äº†ä½œè€…åœ¨ç¡¬é«”å‡ç´šçš„ç¶“é©—ã€‚
     
- [æ‰‹æŠŠæ‰‹å¸¶ä½ å­¸ Pytorchã€CUDAã€NVIDIA-SMIã€cuDNNã€Ubuntuã€NGCã€Dockerã€NVIDIA-Docker çš„å®‰è£èˆ‡è¨­å®š](https://blog.twman.org/2020/05/DeepLearning.html)ï¼šè©³ç´°ä»‹ç´¹åœ¨ Ubuntu ä¸Šå®‰è£æ·±åº¦å­¸ç¿’ç’°å¢ƒçš„æ­¥é©Ÿï¼Œåˆ†äº«å¯¦éš›æ“ä½œç¶“é©—ã€‚
   - è©³ç´°ä»‹ç´¹åœ¨ Ubuntu ç³»çµ±ä¸Šå®‰è£èˆ‡é…ç½®æ·±åº¦å­¸ç¿’ç’°å¢ƒçš„æ­¥é©Ÿï¼ŒåŒ…æ‹¬ TensorFlowã€PyTorchã€CUDAã€NVIDIA-SMIã€cuDNNã€NGCã€Docker å’Œ NVIDIA-Docker ç­‰çµ„ä»¶ã€‚
   - åˆ†äº«åœ¨å¯¦éš›æ“ä½œä¸­å¯èƒ½é‡åˆ°çš„æŒ‘æˆ°èˆ‡è§£æ±ºæ–¹æ¡ˆï¼Œä¸¦å¼·èª¿ç¡¬é«”è³‡æºåœ¨æ·±åº¦å­¸ç¿’é–‹ç™¼ä¸­çš„é‡è¦æ€§ã€‚
   - æ–‡ç« é‚„ä»‹ç´¹äº†ä½œè€…åœ¨ç¡¬é«”å‡ç´šæ–¹é¢çš„ç¶“é©—ï¼Œå±•ç¤ºäº†å¾ GIGABYTE GTX 960 4G åˆ° RTX 6000 Ada 48 GB ç­‰é¡¯å¡çš„æ¼”é€²éç¨‹ã€‚
</details>

# Computer-Vision (é›»è…¦è¦–è¦º)


## Segmentation (åœ–åƒåˆ†å‰²)

- [MatAnyone](https://github.com/pq-yang/MatAnyone)ï¼š[è¦–è¨Šæ‘³åœ–MatAnyoneä¾†äº†ï¼Œä¸€æ¬¡æŒ‡å®šå…¨ç¨‹è¿½è¸ªï¼Œé«®çµ²ç´šé‚„åŸ](https://www.jiqizhixin.com/articles/2025-04-17-27)
- [Meta Segment Anything Model 2 (SAM 2)](https://ai.meta.com/sam2/)
   - [60è¡Œç¨‹å¼ç¢¼è¨“ç·´/å¾®èª¿Segment Anything 2](https://mp.weixin.qq.com/s/YfgYCzvi0cXxOFIfQvE_9w)
   - [CLIPSegï¼šImage Segmentation Using Text and Image Prompts](https://github.com/timojl/clipseg)ï¼š[Huggingface Space](https://huggingface.co/spaces/taesiri/CLIPSeg)
      - [å“¥å»·æ ¹å¤§å­¸æå‡ºCLIPSegï¼Œèƒ½åŒæ™‚ä½œä¸‰å€‹åˆ†å‰²ä»»å‹™çš„æ¨¡å‹](https://mp.weixin.qq.com/s/evKssKulZiUssLN71t6_Lw)
      - [SAMèˆ‡CLIPå¼·å¼·è¯æ‰‹ï¼Œå¯¦ç¾22000é¡çš„åˆ†å‰²èˆ‡è­˜åˆ¥](https://mp.weixin.qq.com/s/evKssKulZiUssLN71t6_Lw)
- [SAMURAI](https://yangchris11.github.io/samurai/)
   - [ç„¡éœ€è¨“ç·´æˆ–å¾®èª¿å³å¯å¾—åˆ°ç©©å®šã€æº–ç¢ºçš„è¿½è¹¤æ•ˆæœï¼ KF + SAM2 è§£æ±ºå¿«é€Ÿç§»å‹•æˆ–è‡ªé®æ“‹çš„ç‰©ä»¶è¿½è¹¤å•é¡Œ](https://mp.weixin.qq.com/s/iU3Bk_uO01GWUxAtIBsrWQ)
   - [ç¶“å…¸å¡çˆ¾æ›¼æ¿¾æ³¢å™¨æ”¹é€²å½±ç‰‡ç‰ˆã€Œåˆ†å‰²ä¸€åˆ‡ã€ï¼Œç¶²å‹ï¼šå¥½å„ªé›…çš„æ–¹æ³•](https://www.qbitai.com/2024/11/223020.html)
- [Grounded SAM 2: Ground and Track Anything in Videos](https://github.com/IDEA-Research/Grounded-SAM-2)
   - [Grounded-Segment-Anything](https://huggingface.co/spaces/yizhangliu/Grounded-Segment-Anything)
- [SAM2Long](https://github.com/Mark12Ding/SAM2Long)ï¼š[å¤§å¹…æå‡SAM 2æ€§èƒ½ï¼æ¸¯ä¸­æ–‡æå‡ºSAM2Longï¼Œè¤‡é›œé•·è¦–é »çš„åˆ†å‰²æ¨¡å‹](https://mp.weixin.qq.com/s/henvaxGoNgx24NLQV1Qj2w)
- [SAM2-Adapter](https://github.com/tianrun-chen/SAM-Adapter-PyTorch)ï¼š[SAM 2ç„¡æ³•åˆ†å‰²ä¸€åˆ‡ï¼Ÿ SAM2-Adapterï¼šé¦–æ¬¡è®“SAM 2åœ¨ä¸‹æ¸¸ä»»å‹™é©æ‡‰èª¿æ ¡ï¼](https://mp.weixin.qq.com/s/3z-LshKAgbSzNCzyoLOuag)
- [SAM2Point](https://github.com/ZiyuGuo99/SAM2Point)ï¼š[å¯æç¤º3D åˆ†å‰²ç ”ç©¶é‡Œç¨‹ç¢‘ï¼ SAM2Pointï¼šSAM2åŠ æŒå¯æ³›åŒ–ä»»3Då ´æ™¯ã€ä»»æ„æç¤ºï¼](https://mp.weixin.qq.com/s/TnTK5UE7O_hcrNzloxBmAw)



## Diffusion model (æ“´æ•£æ¨¡å‹)

- 2025-04-22ï¼š[MAGI-1](https://github.com/SandAI-org/Magi-1)ï¼š[Sand AI å‰µæ¥­åœ˜éšŠæ¨å‡ºäº†å…¨çƒé¦–å€‹è‡ªå›æ­¸å½±ç‰‡ç”Ÿæˆå¤§æ¨¡å‹MAGI-1ï¼Œè©²æ¨¡å‹æœ‰å“ªäº›æ•ˆèƒ½äº®é»ï¼Ÿ](https://www.zhihu.com/question/1898030232184795448)
- 2025-04-22ï¼š[SkyReels V2](https://github.com/SkyworkAI/SkyReels-V2)ï¼š[å…¨çƒé¦–å€‹ç„¡é™æ™‚é•·å½±ç‰‡ç”Ÿæˆï¼æ–°æ“´æ•£æ¨¡å¼å¼•çˆ†å…†å¸‚å ´ï¼Œé›»å½±ç´šç†è§£ï¼Œå…¨é¢é–‹æº](https://www.qbitai.com/2025/04/275531.html)
- 2025-04-14ï¼š[fantasy-talking](https://fantasy-amap.github.io/fantasy-talking/)ï¼š[è§£è®€æœ€æ–°åŸºæ–¼Wan2.1çš„éŸ³è¨Šé©…å‹•æ•¸ä½äººFantasyTalking](https://zhuanlan.zhihu.com/p/1892895916354148118)
- 2025-03-10ï¼š[HunyuanVideo-I2V](https://github.com/Tencent/HunyuanVideo-I2V)ï¼š[é¨°è¨Šé–‹æºHunyuanVideo-I2Våœ–ç”Ÿè¦–è¨Šæ¨¡å‹+LoRAè¨“ç·´è…³æœ¬ï¼Œç¤¾ç¾¤éƒ¨ç½²ã€æ¨ç†å¯¦æˆ°æ•™å­¸ä¾†å§](https://zhuanlan.zhihu.com/p/29110060025)
- 2025-02-25ï¼š[Wan-Video](https://github.com/Wan-Video/Wan2.1)ï¼š[è¶…è¶ŠSoraï¼é˜¿é‡Œè¬ç›¸å¤§æ¨¡å‹æ­£å¼é–‹æºï¼å…¨æ¨¡æ…‹ã€å…¨å°ºå¯¸å¤§æ¨¡å‹é–‹æº](https://finance.sina.com.cn/jjxw/2025-02-26/doc-inemukxr9127437.shtml)
- 2025-02-14ï¼š[FlashVideo](https://github.com/FoundationVision/FlashVideo)ï¼š[ä¾†è‡ªä½å…ƒçµ„çš„è¦–è¨Šå¢å¼·å…¨æ–°é–‹æºæ¼”ç®—æ³•ï¼Œ102ç§’ç”¢ç”Ÿ1080Pè¦–é »](https://zhuanlan.zhihu.com/p/23702953115)
- 2025-01-28ï¼š[Sana](https://github.com/NVlabs/Sana)ï¼š[ICLR 2025 Oral] Efficient High-Resolution Image Synthesis with Linear Diffusion Transformerï¼›[æ¯”FLUXå¿«100å€ï¼è‹±å‰é”è¯æ‰‹MITã€æ¸…è¯é–‹æºè¶…å¿«AIå½±åƒç”¢ç”Ÿæ¨¡å‹](https://zhuanlan.zhihu.com/p/19489214543)
- [Flux](https://huggingface.co/black-forest-labs)
   - [Flux.1-canny-dev](https://huggingface.co/spaces/black-forest-labs/FLUX.1-canny-dev)ï¼š[https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev/](https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev/)
   - [Flux.1-depth-dev](https://huggingface.co/spaces/black-forest-labs/FLUX.1-Depth-dev)ï¼š[https://huggingface.co/black-forest-labs/FLUX.1-Depth-dev/](https://huggingface.co/black-forest-labs/FLUX.1-Depth-dev/)
   - [Flux.1-fill-dev](https://huggingface.co/spaces/black-forest-labs/FLUX.1-Fill-dev)ï¼š[https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev/](https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev/)
   - [Flux.1-redux-dev](https://huggingface.co/spaces/black-forest-labs/FLUX.1-Redux-dev)ï¼š[https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev/](https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev/)
      - 2024-11-26ï¼š[Fluxå®˜æ–¹é‡ç¹ª+æ“´åœ–+é¢¨æ ¼åƒè€ƒ+ControlNet](https://mp.weixin.qq.com/s/Kj1nyJNTpoZ94JjO4FMw_g)
      - 2024-11-25ï¼š[æœ€æ–°flux_fill_inpaintæ¨¡å‹é«”é©—ã€‚](https://mp.weixin.qq.com/s/OPknDJXH1_oezSR86c_png)
- 2024-12-17ï¼š[Leffa](https://github.com/franciszzj/Leffa)ï¼š[Leffaï¼šMeta AI é–‹æºç²¾ç¢ºæ§åˆ¶äººç‰©å¤–è§€å’Œå§¿å‹¢çš„åœ–åƒç”Ÿæˆæ¡†æ¶ï¼Œåœ¨ç”Ÿæˆç©¿è‘—çš„åŒæ™‚ä¿æŒäººç‰©ç‰¹å¾µ](https://juejin.cn/post/7449325873725276196)
- 2024-11-29ï¼š[PuLID, Pure and Lightning ID Customization via Contrastive Alignment](https://github.com/ToTheBeginning/PuLID)ï¼š[https://github.com/balazik/ComfyUI-PuLID-Flux](https://github.com/balazik/ComfyUI-PuLID-Flux)
   - 2024-11-07ï¼š[æå®šComfyUI-PuLID-Fluxç¯€é»åªè¦é€™å¹¾æ­¥ï¼é™„ä¸€éµå£“ç¸®åŒ…](https://mp.weixin.qq.com/s/07BMFHaSasl7-PFtkN6_Zg)
   - 2024-10-08ï¼š[ä¸€æ–‡ææ‡‚PuLID FLUXäººç‰©æ›è‡‰&é¢¨æ ¼é·ç§»](https://mp.weixin.qq.com/s/V-2Cp8_xFnHQNFn35aGdLg)
- 2024-11-26ï¼š[MagicQuill](https://github.com/magic-quill/MagicQuill)ï¼š[https://huggingface.co/spaces/AI4Editing/MagicQuill](https://huggingface.co/spaces/AI4Editing/MagicQuill)
   - [MagicQuillï¼Œç™»ä¸ŠHuggingfaceè¶¨å‹¢æ¦œæ¦œé¦–çš„AI Påœ–ç¥å™¨](https://mp.weixin.qq.com/s/Pc3xRP8_9BxkVSRNznkplw)
- 2024-11-26ï¼š[OOTDiffusion](https://github.com/levihsu/OOTDiffusion)ï¼š[https://huggingface.co/spaces/levihsu/OOTDiffusion](https://huggingface.co/spaces/levihsu/OOTDiffusion)
   - [é–‹æºAIæ›è£ç¥å™¨OOTDiffusion](https://mp.weixin.qq.com/s/B2rNCjJLo8coYzoHGPnVaw)
- 2024-11-24ï¼š[Comfyui Impact Pack](https://github.com/ltdrdata/ComfyUI-Impact-Pack)
   - [Comfyui æœ€å¼·è‡‰éƒ¨ä¿®å¾©å·¥å…·Impact Pack](https://mp.weixin.qq.com/s/hNQ9BfdGbRQ_Osus-yMJWg)
- 2024-11-05ï¼š[ComfyUI OmniGen @ åŒ—äº¬äººå·¥æ™ºæ…§ç ”ç©¶é™¢](https://github.com/AIFSH/OmniGen-ComfyUI)ï¼š[https://huggingface.co/spaces/Shitao/OmniGen](https://huggingface.co/spaces/Shitao/OmniGen)
   - [ComfyUI å½±åƒç”Ÿæˆæ¨¡å‹OmniGenï¼Œäººç‰©ä¸€è‡´æ€§è™•ç†çš„ä¹Ÿå¤ªå¥½äº†](https://mp.weixin.qq.com/s/msGK0FmNs3T3jbUBHfR9DA)
   - [å…¨èƒ½å½±åƒç”Ÿæˆæ¨¡å‹OmniGenï¼šå‘Šåˆ¥ControlNetã€ipadapterç­‰æ’ä»¶ï¼Œåƒ…æ†‘æç¤ºå³å¯æ§åˆ¶å½±åƒç”Ÿæˆèˆ‡ç·¨è¼¯](https://mp.weixin.qq.com/s/48HmqRGBOK1uBdzlprdKSA)


## Digital Human (è™›æ“¬æ•¸å­—äºº)
- [HeyGem](https://github.com/GuijiAI/HeyGem.ai)ï¼š[é–‹æºæ•¸ä½äººå…‹éš†ç¥å™¨](https://zhuanlan.zhihu.com/p/29274862393)
- [Duix](https://github.com/GuijiAI/duix.ai)ï¼š[å…¨çƒé¦–å€‹çœŸäººæ•¸ä½äººï¼Œé–‹æºäº†](https://zhuanlan.zhihu.com/p/716583514)
- [Linly-Talker](https://github.com/Kedreamix/Linly-Talker)ï¼šan intelligent AI system that combines large language models (LLMs) with visual models to create a novel human-AI interaction method. 
- [EchoMimicV2](https://github.com/antgroup/echomimic_v2)ï¼š[CVPR 2025] EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation
- [Hallo3](https://github.com/fudan-generative-vision/hallo3)ï¼š[CVPR 2025] Highly Dynamic and Realistic Portrait Image Animation with Diffusion Transformer Networks
- [MimicTalk](https://github.com/yerfor/MimicTalk)ï¼š[NeurIPS 2024] MimicTalk: Mimicking a personalized and expressive 3D talking face in minutes
- [JoyGen](https://github.com/JOY-MM/JoyGen)ï¼šAudio-Driven 3D Depth-Aware Talking-Face Video Editing
- [Latentsync](https://github.com/bytedance/LatentSync)
- [MuseTalk](https://github.com/TMElyralab/MuseTalk)



## Image Recognition (åœ–åƒè­˜åˆ¥)

- [ViTï¼ˆVision Transformerï¼‰è§£æ](https://zhuanlan.zhihu.com/p/445122996)ï¼šhttps://github.com/google-research/vision_transformer

- [2040å¼µåœ–ç‰‡è¨“ç·´å‡ºçš„ViTï¼Œæº–ç¢ºç‡96.7%ï¼Œé€£é·ç§»è¡¨ç¾éƒ½ä»¤äººé©šè¨](https://zhuanlan.zhihu.com/p/463608959)

- [Swin Transformer: ç”¨CNNçš„æ–¹å¼æ‰“æ•—CNN](https://zhuanlan.zhihu.com/p/362690149)ï¼šhttps://github.com/microsoft/Swin-Transformer

- [EfficientNetV2éœ‡æ’¼ç™¼å¸ƒï¼æ›´å°çš„æ¨¡å‹ï¼Œæ›´å¿«çš„è¨“ç·´](https://zhuanlan.zhihu.com/p/361873583)ï¼šhttps://github.com/d-li14/efficientnetv2.pytorch

## Optical Character Recognition (å…‰å­¸æ–‡å­—è­˜åˆ¥)

**[é‡å°ç‰©ä»¶æˆ–å ´æ™¯å½±åƒé€²è¡Œåˆ†æèˆ‡åµæ¸¬](https://www.twman.org/AI/CV)**
- 2025-03-05ï¼š[PP-DocBee](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/deploy/ppdocbee)ï¼š[ç™¾åº¦æ¨å‡ºæ–‡ä»¶å½±åƒç†è§£PP-DocBee](https://zhuanlan.zhihu.com/p/28715553656)
- 2025-03-03ï¼š[olmocr](https://github.com/allenai/olmocr)ï¼š[ğŸš€æœ¬åœ°éƒ¨ç½²æœ€å¼ºOCRå¤§æ¨¡å‹olmOCRï¼æ”¯æŒç»“æ„åŒ–ç²¾å‡†æå–å¤æ‚PDFæ–‡ä»¶å†…å®¹ï¼](https://www.aivi.fyi/llms/deploy-olmOCR)
- 2025-02-05ï¼š[MinerU](https://github.com/opendatalab/MinerU)ï¼š[å°‡PDFè½‰æ›ç‚ºæ©Ÿå™¨å¯è®€æ ¼å¼çš„ç¥å™¨](https://mp.weixin.qq.com/s/ci5wp6gICTCtaRZfn5yWUQ)
- 2024-12-15ï¼š[markitdown](https://github.com/microsoft/markitdown)
- 2024-09-22ï¼š[OCR2.0æ—¶ä»£-GOTæ¥å•¦ï¼](https://mp.weixin.qq.com/s/W-Ult-F3pU6Wvx3fHEN8yA)
- 2024-09-11ï¼š[GOT-OCR-2.0æ¨¡å‹å¼€æº](https://mp.weixin.qq.com/s/rQL-Q0TGhT6e8Ti4zZalrg)
- 2024-08-20ï¼š[è¬ç‰©çš†å¯AIåŒ–ï¼å‰›é–‹æºå°±æœ‰12000äººåœè§€çš„OCR æƒæPDF é–‹æºå·¥å…·ï¼é‚„å¯è½‰æ›ç‚ºMarkDownï¼](https://www.53ai.com/news/MultimodalLargeModel/2024082059736.html)
- [advancedliteratemachinery/OCR/OmniParser](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/OmniParser)
- 2024-10-29ï¼š[Alibabaå‡ºå“:OmniParseré€šç”¨æ–‡æª”è¤‡é›œå ´æ™¯ä¸‹OCRæŠ½å–](https://mp.weixin.qq.com/s/_1Aatpna7poIVRhfYk4aAQ)
- [RapidOCR](https://github.com/RapidAI/RapidOCR/blob/main/docs/README_zh.md)
- [12å€‹æµè¡Œçš„é–‹æºå…è²»OCRé …ç›®](https://mp.weixin.qq.com/s/7EuhnQedAX6injBL_Dg_sQ)
- [ç”¨PaddleOCRçš„PPOCRLabelä¾†å¾®èª¿é†«ç™‚è¨ºæ–·æ›¸å’Œæ”¶æ“š](https://blog.twman.org/2023/07/wsl.html)
- [TableStructureRec: è¡¨æ ¼çµæ§‹è¾¨è­˜æ¨ç†åº«ä¾†äº†](https://zhuanlan.zhihu.com/p/668484933)ï¼šhttps://github.com/RapidAI/TableStructureRec

## Document Understanding (æ–‡ä»¶ç†è§£)

[Geewook Kim, Teakgyu Hong, Moonbin Yim, JeongYeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park, "OCR-free Document Understanding Transformer", arXiv preprint, arXiv:2111.15664, 2022.](./donut.md)

## Document Layout Analysis (æ–‡ä»¶çµæ§‹åˆ†æ)

[Zejiang Shen, Ruochen Zhang, Melissa Dell, Benjamin Charles Germain Lee, Jacob Carlson, Weining Li, "A unified toolkit for Deep Learning Based Document Image Analysis", arXiv preprint, arXiv:2103.15348, 2021.](./LayoutParser.md)

<details open>
<summary><strong>LayoutLM series</strong></summary>

- **arXiv-2020**:[Yiheng Xu,Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou,"LayoutLM: Pre-training of Text and Layout for Document Image Understanding",arXiv:1912.13318, 2020](./LayoutLM.md)
- **arXiv-2021**:[Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou,"LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding",arXiv:2012.14740, 2021](./LayoutLMv2.md)
- **arXiv-2021**:[Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei, "LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding", arXiv:2104.08836](./LayoutXLM.md)
- **arXiv-2022**:[Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu and Furu Wei, "LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking", arXiv preprint, arXiv:2204.08387, 2022.](./LayoutLMv3.md)
</details>

[Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park,"OCR-free Document Understanding Transformer",arXiv:2111.15664,2022](./donut.md)

[Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li and Furu Wei, "TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models", arXiv preprint, arXiv:2109.10282, 2021](./TrOCR.md)

[Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang and Furu Wei, "DiT: Self-supervised Pre-training for Document Image Transformer", arXiv preprint, arXiv:2203.02378, 2022.](./DiT.md) 

## Text Recognition (æ–‡å­—è­˜åˆ¥)
Lukas Blecher, Guillem Cucurull, Thomas Scialom and Robert Stojnic, "Nougat: Neural Optical Understanding for Academic Documents", arXiv:2308.13418, 2023.
https://facebookresearch.github.io/nougat/
https://www.jiqizhixin.com/articles/2023-08-30-3

[Shancheng Fang, Hongtao Xie, Yuxin Wang, Zhendong Mao, Yongdong Zhang, "Read Like Humans: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition", arXiv:2103.06495, 2021.](./ABINet.md)

[Shancheng Fang, Zhendong Mao, Hongtao Xie, Yuxin Wang, Chenggang Yan, Yongdong Zhang,"ABINet++: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Spotting",arXiv:2211.10578, 2022](./ABINet%2B%2B.md)

[Yuliang Liu, Chunhua Shen, Lianwen Jin, Tong He, Peng Chen, Chongyu Liu, Hao Chen, "ABCNet v2: Adaptive Bezier-Curve Network for Real-time End-to-end Text Spotting", arXiv preprint, 	arXiv:2105.03620, 2021.](./ABCNet_v2.md)

[Yongkun Du, Zhineng Chen, Caiyan Jia, Xiaoting Yin, Tianlun Zheng, Chenxia Li, Yuning Du, Yu-Gang Jiang, "SVTR: Scene Text Recognition with a Single Visual Model", arXiv:2205.00159,2022](./SVTR.md)

## DeepFake Detection (æ·±åº¦å½é€ åµæ¸¬)
H. Zhao, et al., "Multi-attentional Deepfake Detection", Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021, Nashville, TN, USA, 2021, pp. 2185-2194.


Sun, Zekun and Han, Yujie and Hua, Zeyu and Ruan, Na and Jia, Weijia, "Improving the Efficiency and Robustness of Deepfakes Detection through Precise Geometric Features", Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021.

Xiangyu Zhu, Hao Wang, Hongyan Fei, Zhen Lei, and Stan Z. Li, "Face Forgery Detection by 3D Decomposition", Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021.
